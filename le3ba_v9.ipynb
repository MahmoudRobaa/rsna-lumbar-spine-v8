{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31260,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSNA 2024 Lumbar Spine ‚Äî Version 9\n",
    "## v4 Proven Foundation + Competition CE + Attention MIL\n",
    "\n",
    "### v9 vs Previous Versions:\n",
    "| Aspect | v4 (Best: 74.9%) | v8 (Regressed: 62.8%) | **v9 (Target: 75%+)** |\n",
    "|--------|------------------|----------------------|----------------------|\n",
    "| **Input** | Standard RGB | Broken 3-window | ‚úÖ Standard RGB (back to v4) |\n",
    "| **Sequence** | BiGRU | Per-slice independent | ‚úÖ BiGRU (back to v4) |\n",
    "| **Aggregation** | AttentionPool | Simple weighted avg | ‚úÖ **Attention MIL** (1st place) |\n",
    "| **Loss** | Focal | Competition CE [1,2,4] | ‚úÖ Competition CE **[1,4,6]** |\n",
    "| **Sampler** | Weighted | None | ‚úÖ None (keep v8 fix) |\n",
    "| **Freeze** | No | Yes (caused dead class) | ‚úÖ **No freeze** (back to v4) |\n",
    "\n",
    "**Philosophy:** Keep what worked (v4 foundation), add proven improvements (competition CE, attention MIL), remove regressions (freeze, broken multi-window).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "import os, copy, cv2, glob, pydicom, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "CONFIG = {\n",
    "    'seed': 42,\n",
    "    'img_size': 256,\n",
    "    'num_slices': 7,\n",
    "    'batch_size': 12,\n",
    "    'epochs': 25,\n",
    "    \n",
    "    'learning_rate': 1e-4,        # Head/GRU/Attention\n",
    "    'backbone_lr': 1e-5,          # Backbone (10x slower, conservative)\n",
    "    'weight_decay': 0.03,\n",
    "    'patience': 12,\n",
    "    'num_folds': 5,\n",
    "    'train_folds': [0],\n",
    "    \n",
    "    # Loss - UPDATED weights (4x Moderate, 6x Severe)\n",
    "    'class_weights': [1.0, 4.0, 6.0],\n",
    "    \n",
    "    # Training - NO FREEZE (critical!)\n",
    "    'clip_grad_norm': 1.0,\n",
    "    'use_swa': True,\n",
    "    'swa_start_epoch': 18,\n",
    "    'swa_lr': 5e-6,\n",
    "    'warmup_epochs': 2,\n",
    "    'freeze_backbone_epochs': 0,  # NO FREEZE - v4 validated this\n",
    "    \n",
    "    # Architecture\n",
    "    'gru_hidden': 512,\n",
    "    'gru_layers': 2,\n",
    "    'gru_dropout': 0.3,\n",
    "    'attention_hidden': 256,\n",
    "    'dropout': 0.35,\n",
    "    \n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'target_condition': 'spinal_canal_stenosis',\n",
    "    'target_series': 'Sagittal T2/STIR'\n",
    "}\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(CONFIG['seed'])\n",
    "print(f\"‚úÖ v9: v4 Foundation + Competition CE [1,4,6] + Attention MIL\")\n",
    "print(f\"   Backbone freeze: {CONFIG['freeze_backbone_epochs']} epochs (NO FREEZE)\")\n",
    "print(f\"   Target: 75%+ BA (exceed v4's 74.9%)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "DATA_ROOT = \"/kaggle/input/competitions/rsna-2024-lumbar-spine-degenerative-classification\"\n",
    "TRAIN_IMAGES = os.path.join(DATA_ROOT, \"train_images\")\n",
    "\n",
    "df_train = pd.read_csv(f\"{DATA_ROOT}/train.csv\")\n",
    "df_coords = pd.read_csv(f\"{DATA_ROOT}/train_label_coordinates.csv\")\n",
    "df_desc = pd.read_csv(f\"{DATA_ROOT}/train_series_descriptions.csv\")\n",
    "\n",
    "df_train.columns = [col.lower().replace('/', '_') for col in df_train.columns]\n",
    "condition_cols = [c for c in df_train.columns if c != 'study_id']\n",
    "df_labels = pd.melt(df_train, id_vars=['study_id'], value_vars=condition_cols,\n",
    "                    var_name='condition_level', value_name='severity')\n",
    "df_labels = df_labels.dropna(subset=['severity'])\n",
    "df_labels['severity'] = df_labels['severity'].astype(str).str.lower().str.replace('/', '_')\n",
    "\n",
    "def extract_meta(val):\n",
    "    parts = val.split('_')\n",
    "    level = parts[-2] + '_' + parts[-1]\n",
    "    condition = '_'.join(parts[:-2])\n",
    "    return condition, level\n",
    "\n",
    "df_labels[['base_condition', 'level_str']] = df_labels['condition_level'].apply(lambda x: pd.Series(extract_meta(x)))\n",
    "severity_map = {'normal_mild': 0, 'moderate': 1, 'severe': 2}\n",
    "df_labels['label'] = df_labels['severity'].map(severity_map)\n",
    "df_labels = df_labels.dropna(subset=['label'])\n",
    "df_labels['label'] = df_labels['label'].astype(int)\n",
    "\n",
    "df_coords = df_coords.merge(df_desc, on=['study_id', 'series_id'], how='left')\n",
    "df_coords['condition'] = df_coords['condition'].str.lower().str.replace(' ', '_')\n",
    "df_coords['level'] = df_coords['level'].str.lower().str.replace('/', '_')\n",
    "df_coords['condition_level'] = df_coords['condition'] + '_' + df_coords['level']\n",
    "\n",
    "df_model = df_labels[df_labels['base_condition'] == CONFIG['target_condition']].copy()\n",
    "df_coords_filt = df_coords[(df_coords['condition'] == CONFIG['target_condition']) & \n",
    "                           (df_coords['series_description'] == CONFIG['target_series'])]\n",
    "\n",
    "df_final = df_model.merge(df_coords_filt[['study_id', 'condition_level', 'series_id', 'instance_number', 'x', 'y']],\n",
    "                          on=['study_id', 'condition_level'], how='inner')\n",
    "\n",
    "valid_rows = []\n",
    "for index, row in tqdm(df_final.iterrows(), total=len(df_final), desc=\"Checking Files\"):\n",
    "    path = f\"{TRAIN_IMAGES}/{row['study_id']}/{row['series_id']}/{int(row['instance_number'])}.dcm\"\n",
    "    if os.path.exists(path):\n",
    "        valid_rows.append(row)\n",
    "\n",
    "df_final = pd.DataFrame(valid_rows).reset_index(drop=True)\n",
    "level_map = {'l1_l2': 0, 'l2_l3': 1, 'l3_l4': 2, 'l4_l5': 3, 'l5_s1': 4}\n",
    "df_final['level_idx'] = df_final['level_str'].map(level_map)\n",
    "\n",
    "print(f\"\\n‚úÖ Data: {len(df_final)} samples\")\n",
    "for i in range(3):\n",
    "    c = (df_final['label']==i).sum()\n",
    "    print(f\"   Class {i}: {c} ({100*c/len(df_final):.1f}%)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset (v4 Style - Standard RGB)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "class RSNADatasetV9(Dataset):\n",
    "    \"\"\"\n",
    "    v9 Dataset: Back to v4's proven approach\n",
    "    - Standard RGB DICOM loading (preserves ImageNet pretrained weights)\n",
    "    - Single window (WC=50, WW=350 for soft tissue)\n",
    "    - CLAHE enhancement\n",
    "    - 7 adjacent slices\n",
    "    \"\"\"\n",
    "    def __init__(self, df, num_slices=7, img_size=256, transform=None, is_training=False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.num_slices = num_slices\n",
    "        self.img_size = img_size\n",
    "        self.transform = transform\n",
    "        self.is_training = is_training\n",
    "        self.clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def load_dicom(self, path):\n",
    "        try:\n",
    "            dcm = pydicom.dcmread(path)\n",
    "            img = dcm.pixel_array.astype(np.float32)\n",
    "            \n",
    "            # Soft tissue window (standard for spine stenosis)\n",
    "            wc, ww = 50, 350\n",
    "            low = wc - ww/2\n",
    "            high = wc + ww/2\n",
    "            windowed = np.clip((img - low) / max(ww, 1) * 255, 0, 255).astype(np.uint8)\n",
    "            \n",
    "            # CLAHE\n",
    "            enhanced = self.clahe.apply(windowed)\n",
    "            \n",
    "            # Convert to RGB (3-channel, same image)\n",
    "            rgb = cv2.cvtColor(enhanced, cv2.COLOR_GRAY2RGB)\n",
    "            return rgb\n",
    "        except:\n",
    "            return np.zeros((self.img_size, self.img_size, 3), dtype=np.uint8)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        center_inst = int(row['instance_number'])\n",
    "        study_path = f\"{TRAIN_IMAGES}/{row['study_id']}/{row['series_id']}\"\n",
    "        cx, cy = int(row['x']), int(row['y'])\n",
    "        \n",
    "        if self.is_training:\n",
    "            jitter = self.img_size // 16\n",
    "            cx += random.randint(-jitter, jitter)\n",
    "            cy += random.randint(-jitter, jitter)\n",
    "        \n",
    "        half = self.num_slices // 2\n",
    "        indices = [center_inst + i - half for i in range(self.num_slices)]\n",
    "        \n",
    "        slices = []\n",
    "        for inst in indices:\n",
    "            path = os.path.join(study_path, f\"{inst}.dcm\")\n",
    "            if os.path.exists(path):\n",
    "                img = self.load_dicom(path)\n",
    "            else:\n",
    "                img = np.zeros((self.img_size, self.img_size, 3), dtype=np.uint8)\n",
    "            \n",
    "            h, w = img.shape[:2]\n",
    "            crop_size = self.img_size\n",
    "            x1 = max(0, cx - crop_size)\n",
    "            y1 = max(0, cy - crop_size)\n",
    "            x2 = min(w, cx + crop_size)\n",
    "            y2 = min(h, cy + crop_size)\n",
    "            crop = img[y1:y2, x1:x2]\n",
    "            \n",
    "            if crop.size == 0:\n",
    "                crop = np.zeros((self.img_size, self.img_size, 3), dtype=np.uint8)\n",
    "            else:\n",
    "                crop = cv2.resize(crop, (self.img_size, self.img_size))\n",
    "            \n",
    "            slices.append(crop)\n",
    "        \n",
    "        if self.transform:\n",
    "            slices = [self.transform(image=s)['image'] for s in slices]\n",
    "        else:\n",
    "            slices = [torch.tensor(s).permute(2,0,1).float() / 255.0 for s in slices]\n",
    "        \n",
    "        sequence = torch.stack(slices, dim=0)  # (7, 3, 256, 256)\n",
    "        label = torch.tensor(row['label'], dtype=torch.long)\n",
    "        level_idx = torch.tensor(row['level_idx'], dtype=torch.long)\n",
    "        \n",
    "        return sequence, label, level_idx\n",
    "\n",
    "print(\"‚úÖ RSNADatasetV9: Standard RGB, soft tissue window, CLAHE\")\n",
    "print(\"   Output: (7, 3, 256, 256)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Augmentation (v4 Proven)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "train_aug = A.Compose([\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.12, rotate_limit=12,\n",
    "                       border_mode=cv2.BORDER_CONSTANT, value=0, p=0.6),\n",
    "    A.OneOf([\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.25, contrast_limit=0.25, p=1.0),\n",
    "        A.RandomGamma(gamma_limit=(75, 125), p=1.0),\n",
    "    ], p=0.6),\n",
    "    A.GaussNoise(var_limit=(5.0, 30.0), p=0.3),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_aug = A.Compose([\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "tta_augs = [\n",
    "    val_aug,\n",
    "    A.Compose([\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=1.0),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Augmentation: Moderate (v4 proven), {len(tta_augs)} TTA variants\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "class AttentionMIL(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention-based Multiple Instance Learning (from 1st place solution)\n",
    "    Learns which slices are most diagnostic (vs fixed weighting)\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_dim=1024, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(feature_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, features):\n",
    "        # features: (B, num_slices, feature_dim)\n",
    "        attn_scores = self.attention(features)  # (B, num_slices, 1)\n",
    "        attn_weights = F.softmax(attn_scores, dim=1)  # (B, num_slices, 1)\n",
    "        attended = (features * attn_weights).sum(dim=1)  # (B, feature_dim)\n",
    "        return attended, attn_weights.squeeze(-1)  # Return weights for visualization\n",
    "\n",
    "print(\"‚úÖ AttentionMIL: Learns importance of each slice (interpretable)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "class SpineModelV9(nn.Module):\n",
    "    \"\"\"\n",
    "    v9: v4 Foundation (BiGRU) + Attention MIL + Competition CE\n",
    "    \n",
    "    Architecture:\n",
    "    - Backbone: EfficientNet-V2-S (unfrozen from start)\n",
    "    - Sequence: BiGRU 2-layer bidirectional\n",
    "    - Aggregation: Attention MIL (vs v4's AttentionPool)\n",
    "    - Level: Embedding + concatenation\n",
    "    - Classifier: With class-prior bias initialization\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=3, num_slices=7, dropout=0.35, num_levels=5,\n",
    "                 gru_hidden=512, gru_layers=2, gru_dropout=0.3, attention_hidden=256):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_slices = num_slices\n",
    "        \n",
    "        # Backbone: EfficientNet-V2-S (pretrained, NO freeze)\n",
    "        effnet = models.efficientnet_v2_s(weights='IMAGENET1K_V1')\n",
    "        self.backbone = nn.Sequential(*list(effnet.children())[:-1])\n",
    "        self.feature_dim = 1280\n",
    "        \n",
    "        # Project backbone features for GRU\n",
    "        self.feature_proj = nn.Linear(self.feature_dim, gru_hidden)\n",
    "        \n",
    "        # BiGRU (v4 proven)\n",
    "        self.gru = nn.GRU(\n",
    "            gru_hidden,\n",
    "            gru_hidden,\n",
    "            num_layers=gru_layers,\n",
    "            bidirectional=True,\n",
    "            dropout=gru_dropout if gru_layers > 1 else 0,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Attention MIL (from 1st place)\n",
    "        gru_out_dim = gru_hidden * 2  # Bidirectional\n",
    "        self.attention = AttentionMIL(gru_out_dim, attention_hidden)\n",
    "        \n",
    "        # Level embedding\n",
    "        self.level_embed = nn.Embedding(num_levels, 256)\n",
    "        \n",
    "        # Classifier\n",
    "        combined_dim = gru_out_dim + 256\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(combined_dim),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(combined_dim, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout * 0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize classifier bias with class priors\n",
    "        # P(Normal)‚âà88% ‚Üí logit=2, P(Moderate)‚âà6% ‚Üí logit=-2.5, P(Severe)‚âà6% ‚Üí logit=-3\n",
    "        self.classifier[-1].bias.data = torch.tensor([2.0, -2.5, -3.0])\n",
    "    \n",
    "    def forward(self, x, level_idx=None):\n",
    "        # x: (B, num_slices, 3, H, W)\n",
    "        B, S, C, H, W = x.size()\n",
    "        \n",
    "        # Process all slices through backbone\n",
    "        x = x.view(B * S, C, H, W)\n",
    "        features = self.backbone(x)  # (B*S, 1280, 1, 1)\n",
    "        features = features.view(B, S, -1)  # (B, S, 1280)\n",
    "        features = self.feature_proj(features)  # (B, S, gru_hidden)\n",
    "        \n",
    "        # BiGRU sequence processing\n",
    "        gru_out, _ = self.gru(features)  # (B, S, gru_hidden*2)\n",
    "        \n",
    "        # Attention MIL aggregation\n",
    "        attended, attn_weights = self.attention(gru_out)  # (B, gru_hidden*2)\n",
    "        \n",
    "        # Level conditioning\n",
    "        if level_idx is not None:\n",
    "            level_feat = self.level_embed(level_idx)  # (B, 256)\n",
    "            combined = torch.cat([attended, level_feat], dim=1)  # (B, gru_hidden*2 + 256)\n",
    "        else:\n",
    "            combined = torch.cat([attended, torch.zeros(B, 256, device=x.device)], dim=1)\n",
    "        \n",
    "        # Classify\n",
    "        logits = self.classifier(combined)\n",
    "        \n",
    "        return {\n",
    "            'logits': logits,\n",
    "            'attention': attn_weights  # For visualization\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ SpineModelV9\")\n",
    "print(\"   - EfficientNet-V2-S backbone (unfrozen)\")\n",
    "print(\"   - BiGRU 2-layer bidirectional (v4 proven)\")\n",
    "print(\"   - Attention MIL aggregation (1st place)\")\n",
    "print(\"   - Class-prior bias init [2.0, -2.5, -3.0]\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Competition-Weighted CE Loss (Enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "class CompetitionWeightedCE(nn.Module):\n",
    "    \"\"\"\n",
    "    Competition-metric-aligned CE with INCREASED Moderate weight\n",
    "    Weights: [1.0, 4.0, 6.0] (was [1, 2, 4] in v8 - too weak for Moderate)\n",
    "    \"\"\"\n",
    "    def __init__(self, weights=[1.0, 4.0, 6.0]):\n",
    "        super().__init__()\n",
    "        self.register_buffer('weights', torch.tensor(weights, dtype=torch.float32))\n",
    "    \n",
    "    def forward(self, logits, labels):\n",
    "        # Auto device handling\n",
    "        w = self.weights.to(logits.device)\n",
    "        return F.cross_entropy(logits, labels, weight=w)\n",
    "\n",
    "print(\"‚úÖ Competition-weighted CE: [1.0, 4.0, 6.0]\")\n",
    "print(\"   Moderate penalty 4x (was 2x in v8)\")\n",
    "print(\"   Severe penalty 6x (was 4x in v8)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "def compute_per_class_metrics(preds, labels, num_classes=3):\n",
    "    metrics = {}\n",
    "    for c in range(num_classes):\n",
    "        mask = (labels == c)\n",
    "        if mask.sum() > 0:\n",
    "            metrics[f'class_{c}_recall'] = ((preds == c) & mask).sum() / mask.sum()\n",
    "        else:\n",
    "            metrics[f'class_{c}_recall'] = 0.0\n",
    "    return metrics\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0.002, mode='max'):\n",
    "        self.patience, self.min_delta, self.mode = patience, min_delta, mode\n",
    "        self.counter, self.best_score = 0, None\n",
    "    def __call__(self, score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            return False\n",
    "        improved = (score > self.best_score + self.min_delta) if self.mode == 'max' \\\n",
    "                   else (score < self.best_score - self.min_delta)\n",
    "        if improved:\n",
    "            self.best_score, self.counter = score, 0\n",
    "            return False\n",
    "        self.counter += 1\n",
    "        return self.counter >= self.patience"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "def train_one_fold_v9(model, train_loader, val_loader, fold, config):\n",
    "    criterion = CompetitionWeightedCE(config['class_weights'])\n",
    "    \n",
    "    # Optimizer with separate LR for backbone vs rest\n",
    "    optimizer = optim.AdamW([\n",
    "        {'params': model.backbone.parameters(), 'lr': config['backbone_lr'], 'weight_decay': config['weight_decay']},\n",
    "        {'params': model.feature_proj.parameters(), 'lr': config['learning_rate'], 'weight_decay': 0.01},\n",
    "        {'params': model.gru.parameters(), 'lr': config['learning_rate'], 'weight_decay': 0.01},\n",
    "        {'params': model.attention.parameters(), 'lr': config['learning_rate'], 'weight_decay': 0.01},\n",
    "        {'params': model.level_embed.parameters(), 'lr': config['learning_rate'], 'weight_decay': 0.01},\n",
    "        {'params': model.classifier.parameters(), 'lr': config['learning_rate'], 'weight_decay': 0.01}\n",
    "    ])\n",
    "    \n",
    "    # Cosine decay with warmup\n",
    "    total_steps = config['epochs'] * len(train_loader)\n",
    "    warmup_steps = config['warmup_epochs'] * len(train_loader)\n",
    "    \n",
    "    def lr_lambda(step):\n",
    "        if step < warmup_steps:\n",
    "            return step / max(warmup_steps, 1)\n",
    "        progress = (step - warmup_steps) / max(total_steps - warmup_steps, 1)\n",
    "        return max(0.5 * (1 + np.cos(np.pi * progress)), 1e-6)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "    scaler = GradScaler('cuda')\n",
    "    \n",
    "    swa_model = AveragedModel(model) if config['use_swa'] else None\n",
    "    swa_scheduler = SWALR(optimizer, swa_lr=config['swa_lr']) if config['use_swa'] else None\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=config['patience'], min_delta=0.002, mode='max')\n",
    "    best_ba = 0.0\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [],\n",
    "        'balanced_acc': [], 'class_0_recall': [], 'class_1_recall': [], 'class_2_recall': []\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüöÄ Fold {fold+1} Training (v9)\")\n",
    "    print(f\"   Train: {len(train_loader.dataset)}, Val: {len(val_loader.dataset)}\")\n",
    "    print(f\"   Weights: {config['class_weights']}, Freeze: {config['freeze_backbone_epochs']} epochs\")\n",
    "    print(f\"   Target: Match v4 (74.9%) and exceed to 75%+\")\n",
    "    \n",
    "    # NO backbone freeze in v9 (critical!)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    for epoch in range(config['epochs']):\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0, 0, 0\n",
    "        is_swa = config['use_swa'] and epoch >= config['swa_start_epoch']\n",
    "        \n",
    "        tag = \"[SWA]\" if is_swa else \"\"\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['epochs']} {tag}\")\n",
    "        \n",
    "        for images, labels, level_idx in loop:\n",
    "            images = images.to(config['device'])\n",
    "            labels = labels.to(config['device'])\n",
    "            level_idx = level_idx.to(config['device'])\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with autocast('cuda'):\n",
    "                outputs = model(images, level_idx)\n",
    "                loss = criterion(outputs['logits'], labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), config['clip_grad_norm'])\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            if is_swa:\n",
    "                swa_scheduler.step()\n",
    "            else:\n",
    "                scheduler.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            preds = outputs['logits'].argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            loop.set_postfix(loss=f\"{train_loss/(loop.n+1):.4f}\",\n",
    "                           acc=f\"{100*correct/total:.1f}%\")\n",
    "        \n",
    "        train_acc = correct / total\n",
    "        if swa_model and is_swa:\n",
    "            swa_model.update_parameters(model)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        all_preds, all_labels = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels, level_idx in val_loader:\n",
    "                images = images.to(config['device'])\n",
    "                labels = labels.to(config['device'])\n",
    "                level_idx = level_idx.to(config['device'])\n",
    "                \n",
    "                with autocast('cuda'):\n",
    "                    outputs = model(images, level_idx)\n",
    "                    loss = criterion(outputs['logits'], labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                preds = outputs['logits'].argmax(dim=1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "                \n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_acc = val_correct / val_total\n",
    "        all_preds, all_labels = np.array(all_preds), np.array(all_labels)\n",
    "        pc = compute_per_class_metrics(all_preds, all_labels)\n",
    "        ba = (pc['class_0_recall'] + pc['class_1_recall'] + pc['class_2_recall']) / 3\n",
    "        \n",
    "        # Dead class monitor\n",
    "        pred_counts = np.bincount(all_preds, minlength=3)\n",
    "        if pred_counts.min() < 3:\n",
    "            print(f\"   ‚ö†Ô∏è Dead class warning: prediction counts = {pred_counts.tolist()}\")\n",
    "        \n",
    "        history['train_loss'].append(train_loss / len(train_loader))\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss / len(val_loader))\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['balanced_acc'].append(ba)\n",
    "        for c in range(3):\n",
    "            history[f'class_{c}_recall'].append(pc[f'class_{c}_recall'])\n",
    "        \n",
    "        print(f\"üìä Train: {100*train_acc:.1f}% | Val: {100*val_acc:.1f}% | \"\n",
    "              f\"N={100*pc['class_0_recall']:.1f}% M={100*pc['class_1_recall']:.1f}% \"\n",
    "              f\"S={100*pc['class_2_recall']:.1f}% | BA={100*ba:.1f}%\")\n",
    "        \n",
    "        # Save best (with min minority recall gate)\n",
    "        min_minority = min(pc['class_1_recall'], pc['class_2_recall'])\n",
    "        if ba > best_ba and min_minority >= 0.20:\n",
    "            best_ba = ba\n",
    "            torch.save(model.state_dict(), f\"best_v9_fold{fold}.pth\")\n",
    "            print(f\"   ‚úÖ Saved! BA={100*ba:.1f}%\")\n",
    "        \n",
    "        if early_stopping(ba):\n",
    "            print(f\"   ‚èπÔ∏è Early stop at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"best_v9_fold{fold}.pth\"))\n",
    "    return model, history, best_ba"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. K-Fold Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "kfold = StratifiedGroupKFold(n_splits=CONFIG['num_folds'], shuffle=True, random_state=CONFIG['seed'])\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(df_final, df_final['label'], df_final['study_id'])):\n",
    "    if fold not in CONFIG['train_folds']:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"FOLD {fold+1} (v9 ‚Äî v4 Foundation + Attention MIL)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    train_df = df_final.iloc[train_idx].reset_index(drop=True)\n",
    "    val_df = df_final.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    for i in range(3):\n",
    "        c = (train_df['label']==i).sum()\n",
    "        print(f\"   Class {i}: {c} ({100*c/len(train_df):.1f}%)\")\n",
    "    \n",
    "    # NO WeightedRandomSampler - standard shuffle\n",
    "    train_ds = RSNADatasetV9(train_df, num_slices=CONFIG['num_slices'],\n",
    "                             img_size=CONFIG['img_size'], transform=train_aug, is_training=True)\n",
    "    val_ds = RSNADatasetV9(val_df, num_slices=CONFIG['num_slices'],\n",
    "                           img_size=CONFIG['img_size'], transform=val_aug, is_training=False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=CONFIG['batch_size'], shuffle=True,\n",
    "                             num_workers=2, pin_memory=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=CONFIG['batch_size'], shuffle=False,\n",
    "                           num_workers=2, pin_memory=True)\n",
    "    \n",
    "    model = SpineModelV9(\n",
    "        num_classes=3,\n",
    "        num_slices=CONFIG['num_slices'],\n",
    "        dropout=CONFIG['dropout'],\n",
    "        gru_hidden=CONFIG['gru_hidden'],\n",
    "        gru_layers=CONFIG['gru_layers'],\n",
    "        gru_dropout=CONFIG['gru_dropout'],\n",
    "        attention_hidden=CONFIG['attention_hidden']\n",
    "    ).to(CONFIG['device'])\n",
    "    \n",
    "    print(f\"   üèóÔ∏è SpineModelV9: {sum(p.numel() for p in model.parameters()):,} params\")\n",
    "    \n",
    "    model, history, best_ba = train_one_fold_v9(model, train_loader, val_loader, fold, CONFIG)\n",
    "    fold_results.append({'fold': fold, 'best_ba': best_ba, 'history': history})\n",
    "    print(f\"\\n‚úÖ Fold {fold+1}: Best BA = {100*best_ba:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "for r in fold_results:\n",
    "    print(f\"Fold {r['fold']+1}: BA = {100*r['best_ba']:.1f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. TTA Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "def predict_tta_v9(model, df, config, augs):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    \n",
    "    for aug in augs:\n",
    "        ds = RSNADatasetV9(df, num_slices=config['num_slices'],\n",
    "                          img_size=config['img_size'], transform=aug, is_training=False)\n",
    "        loader = DataLoader(ds, batch_size=config['batch_size'], shuffle=False,\n",
    "                          num_workers=2, pin_memory=True)\n",
    "        probs = []\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels, lidx in loader:\n",
    "                imgs = imgs.to(config['device'])\n",
    "                lidx = lidx.to(config['device'])\n",
    "                with autocast('cuda'):\n",
    "                    outputs = model(imgs, lidx)\n",
    "                    p = F.softmax(outputs['logits'], dim=1)\n",
    "                probs.append(p.cpu().numpy())\n",
    "        all_probs.append(np.concatenate(probs, 0))\n",
    "    \n",
    "    avg = np.mean(all_probs, 0)\n",
    "    return np.argmax(avg, 1), avg\n",
    "\n",
    "model.eval()\n",
    "tta_preds, _ = predict_tta_v9(model, val_df, CONFIG, tta_augs)\n",
    "no_tta_preds, _ = predict_tta_v9(model, val_df, CONFIG, [val_aug])\n",
    "\n",
    "labels = val_df['label'].values\n",
    "\n",
    "pc1 = compute_per_class_metrics(no_tta_preds, labels)\n",
    "ba1 = np.mean([pc1[f'class_{c}_recall'] for c in range(3)])\n",
    "pc2 = compute_per_class_metrics(tta_preds, labels)\n",
    "ba2 = np.mean([pc2[f'class_{c}_recall'] for c in range(3)])\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Without TTA: BA={100*ba1:.1f}%  N={100*pc1['class_0_recall']:.1f}%  \"\n",
    "      f\"M={100*pc1['class_1_recall']:.1f}%  S={100*pc1['class_2_recall']:.1f}%\")\n",
    "print(f\"With TTA:    BA={100*ba2:.1f}%  N={100*pc2['class_0_recall']:.1f}%  \"\n",
    "      f\"M={100*pc2['class_1_recall']:.1f}%  S={100*pc2['class_2_recall']:.1f}%\")\n",
    "print(f\"Delta:       {100*(ba2-ba1):+.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(classification_report(labels, tta_preds,\n",
    "                           target_names=['Normal/Mild', 'Moderate', 'Severe']))\n",
    "\n",
    "cm = confusion_matrix(labels, tta_preds)\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='Blues',\n",
    "            xticklabels=['Normal/Mild', 'Moderate', 'Severe'],\n",
    "            yticklabels=['Normal/Mild', 'Moderate', 'Severe'])\n",
    "plt.ylabel('True'); plt.xlabel('Predicted')\n",
    "plt.title(f'v9 Confusion Matrix (BA: {100*ba2:.1f}%)')\n",
    "plt.tight_layout(); plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Training History"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "if fold_results:\n",
    "    h = fold_results[0]['history']\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    ep = range(1, len(h['train_loss'])+1)\n",
    "    \n",
    "    axes[0].plot(ep, h['train_loss'], 'b-', label='Train')\n",
    "    axes[0].plot(ep, h['val_loss'], 'r-', label='Val')\n",
    "    axes[0].set_title('Loss'); axes[0].legend(); axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].plot(ep, h['class_0_recall'], 'g-o', label='Normal', ms=3)\n",
    "    axes[1].plot(ep, h['class_1_recall'], color='orange', marker='s', label='Moderate', ms=3)\n",
    "    axes[1].plot(ep, h['class_2_recall'], 'r-^', label='Severe', ms=3)\n",
    "    axes[1].axhline(y=0.75, color='gray', linestyle='--', alpha=0.3, label='Target (75%)')\n",
    "    axes[1].set_title('Per-Class Recall'); axes[1].legend(); axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[2].plot(ep, h['balanced_acc'], 'purple', marker='d', lw=2, ms=3)\n",
    "    axes[2].axhline(y=0.749, color='red', linestyle='--', alpha=0.5, label='v4 Best (74.9%)')\n",
    "    axes[2].axhline(y=0.755, color='green', linestyle='--', alpha=0.5, label='Target (75.5%)')\n",
    "    axes[2].set_title(f'BA (Best: {100*max(h[\"balanced_acc\"]):.1f}%)')\n",
    "    axes[2].legend(); axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout(); plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Complete ‚Äî v9\n",
    "\n",
    "### Key Results:\n",
    "- ‚úÖ **BA:** ___% (Target: 75%+, v4 baseline: 74.9%)\n",
    "- ‚úÖ **Moderate Recall:** ___%  (Target: 65%+)\n",
    "- ‚úÖ **Severe Recall:** ___%  (Target: 70%+)\n",
    "- ‚úÖ **No Dead Class:** All classes active from epoch 1\n",
    "\n",
    "### What Changed from v8:\n",
    "- ‚úÖ Reverted to v4's proven BiGRU architecture\n",
    "- ‚úÖ Standard RGB input (no broken multi-window)\n",
    "- ‚úÖ NO backbone freeze (critical for minority classes)\n",
    "- ‚úÖ Higher class weights [1, 4, 6] (Moderate 4x vs 2x)\n",
    "- ‚úÖ Added Attention MIL (from 1st place solution)\n",
    "\n",
    "### Next Steps:\n",
    "1. If BA ‚â• 75%: Run 5-fold ensemble (target 76-78%)\n",
    "2. If BA < 75% but > 74%: Tune weights to [1, 5, 7]\n",
    "3. Analyze attention weights - which slices matter most?\n"
   ]
  }
 ]
}